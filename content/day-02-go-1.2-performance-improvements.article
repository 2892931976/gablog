Go Advent Day 2 - Go 1.2 performance improvements
2 Dec 2013
Tags: goadvent

Dave Cheney

* Introduction

7 months, 1600 changes, well over 350 issues closed¹, and [[http://blog.golang.org/go12][Go 1.2 is done]]. Go and install it now, it's ok, it only takes a few minutes, I'll wait.

When Go 1.1 was released earlier in the year I did a series of posts, [[http://dave.cheney.net/2013/05/21/go-11-performance-improvements][part 1]], [[http://dave.cheney.net/2013/05/25/go-11-performance-improvements-part-2][part 2]], [[http://dave.cheney.net/2013/05/28/go-11-performance-improvements-part-3][part 3]], exploring the performance improvments the then current released provided. Go 1.1 was a herculian development effort, stretching some 14 months and bought with it equally impressive performance improvements.

This time around a 7 month development effort with a fixed delivery date was announced up front. Split equally, contributors spend 3-4 months landing improvements before a 3 month feature freeze. 

Of course, shorter cycles mean less scope for performance improvement, but as we shall discover, Go 1.2 has not failed to deliver.

* The top line number

A widely quoted figure for the Go 1.1 performance improvements was [[http://golang.org/doc/go1.1#performance][30-40%]]. As Go matures it becomes harder to find these big performance gains, and is just as difficult to summarise them in a single sentance. Throughout this article there are links to the raw data in the autobench repository which I encourage you to consult.

* Autobench

As Release Candidates started to arrive in September I took some time to brush the cobwebs off [[https://github.com/davecheney/autobench][autobench]] and put out a call for benchmark contributions. Along the way new benchmarks were contributed from external Go libraries which give an important view on the performance improvements Go 1.2 bring to code outside the standard library.

** Megajson performance
.image day-02-go-1.2-performance-improvements/megajson.png
Ben Johnson's [[https://github.com/benbjohnson/megajson][Megajson]] package shows a 15-25% improvement over Go 1.1.2.

** Snappy performance
.image day-02-go-1.2-performance-improvements/snappy.png
Snappy benchmarks have improved between 

Snappy performance
[amd64, 386, arm]

These images are generated by AJ Starks' great [[http://mindchunk.blogspot.com.au/2013/05/visualizing-go-benchmarks-with-benchviz.html][benchviz]] tool.

* Performance headlines

This next section will highligh some of the major performance improvments that landed in Go 1.2.

** 8k stack segments

Since the earliest days of Go, each goroutine has allocated a stack frames in units of 4096 bytes. Being equal to the default operating system page size made that a sensible value to handle, but it had been known for a long time for code that was recursive or contained inner loops of long call chains (most of the encoding/* packages fall into this category) stack splitting, or stack stradelling was a significant cause of slowdown, and benchmark instability. 

In October Russ Cox proposed changing the default size of the Goroutine stack to 8k, and [[https://codereview.appspot.com/14317043/][presented a detailed analysis to support this change] so late in the development cycle. This one change alone boosted many of the Go 1 benchmarks by 10% alone, but the main clue that this was the right decision was the infamous JsonEncoder benchmark became stable and predictable.

Not without a cost, but this cost is believed to be managable. Russ' data demonstrated that the original 4k stack size was wrong, and as it had been chosen without any empiracl evidence, a number which could not be defended as 'better'

** Preemption

Preemption check on every function entry. 

Easily predictable by cpu branch predictors

http://golang.org/doc/go1.2#preemption

Prevents a single goroutine from monopolising the CPU under *some* conditions.

Lowers the overall GC time by allowing the GC to stop-the-world faster.

** Intergrated network poller

The work that was started by Mikio Hara, Alex Brainman and Dmirty Vyukov in 1.1 integrating the the network polling subsystem directly into the runtime was completed for Windows and the BSD family. All platforms now use the intergrated network poller. This has also resolved [[http://golang.org/issue/5596][the `freebsd/amd64`]] regression noted during Go 1.1.

.image day-02-go-1.2-performance-improvements/freebsd-amd64-http.png

* show runtime benchmarks

** Garbage collector improvements

A large amount of work tool place during the 1.2 cycle to further improve the performance of the garbage collector.

While the garbage collector is not completely precise yet (this work continues in the 1.3 cycle), its precision has improved over Go 1.1, which itself was a major improvement over 1.0.

Improving the precision of the garbage collector means fewer values on the heap are mistaken for pointers. This has the direct result that the heap is smaller. A smaller heap leads to lower garbage collection time overall as well as lowering the memory footprint of Go programs.

Finishing the work of making the garbage collector precise is a major focus of the 1.3 development cycle.

* Faster primatives

In my previous series on Go 1.1 I showed large data sets from the runtime

** Append is faster 

The `append` builtin function was improved in Go 1.1 by Rob Pike to reduce it's overhead when being called on slices with a small number of elements, which is a common operation. During 1.2 this was improved further by [[https://codereview.appspot.com/12815046/][Rémy Oudompheng]] who moved the append operations into the compiler thus reducing the overhead for all append operations.

[benchmark data from 386, amd64, intel]

** Unified strings and bytes primatives

In Go 1.1 `bytes.IndexByte` and `bytes.Equal` received assembly versions for all three architectures which improved their throughput. In Go 1.2 this was improved further by unifying the operation of their counterparts in the `strings` package.

** Memmove improvements



** Http benchmark numbers

** crypto improvements

faster routines for arm, more to come thanks to Nick Craig-Wood
faster des

** compress

faster flate and bzip2, thanks to Remy

Important primative

* Stable sort



* Wrapping up



Fewer low hanging fruit, less big wins

* Looking forward to the 1.3 development cycle

Planning for the 1.3 cycle has been underway for a month now. Rob Pike opened the discussion on the second of November with [[
https://groups.google.com/d/msg/golang-dev/846QFpppXUo/satz-x5kxosJ][this thread]] out of which a [[http://golang.org/s/go13todo][document]] identifying the major items for this cycle.


Shifting focus to real workloads, encoding, compression, encryption, decoding, networking

Renewed focus on toolchain performance. We picked up a 30% speedup in compilation in 1.1, but have paid back most of that over the 1.2 cycle.


Russ Cox has proposed some wide ranging changes to the linker which will move more work to the compiler, thus being parallisable, and reusabe, and has te

Link to rsc' Linker document. [[http://golang.org/s/go13linker]]

Binary size.

Precise GC and copying stacks

Copying stacks will allow stacks to grow when rquired without the cost of straddling the stack segment break. Rust have come to the same conclusion

1. [[https://code.google.com/p/go/issues/list?can=1&q=label%3Ago1.2+OR+label%3Ago1.2maybe+AND+status%3AFixed+&colspec=ID+Status+Stars+Priority+Owner+Reporter+Summary&cells=tiles][Go 1.2 Closed issues]] -- the real number is probably higher, many issues are closed without being tagged for the release they are fixed in.
